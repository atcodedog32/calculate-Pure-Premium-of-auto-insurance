{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Kangaroo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>veh_value</th>\n",
       "      <th>exposure</th>\n",
       "      <th>veh_body</th>\n",
       "      <th>veh_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>dr_age</th>\n",
       "      <th>claim_ind</th>\n",
       "      <th>claim_count</th>\n",
       "      <th>claim_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.241898</td>\n",
       "      <td>STNWG</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.856523</td>\n",
       "      <td>STNWG</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.417517</td>\n",
       "      <td>HBACK</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.626975</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.089770</td>\n",
       "      <td>HBACK</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  veh_value  exposure veh_body  veh_age gender area  dr_age  claim_ind  \\\n",
       "0   3       6.43  0.241898    STNWG        1      M    A       3          0   \n",
       "1   6       4.46  0.856523    STNWG        1      M    A       3          0   \n",
       "2  20       1.70  0.417517    HBACK        1      M    A       4          0   \n",
       "3  21       0.48  0.626975    SEDAN        4      F    A       6          0   \n",
       "4  28       1.96  0.089770    HBACK        1      F    A       2          0   \n",
       "\n",
       "   claim_count  claim_cost  \n",
       "0            0         0.0  \n",
       "1            0         0.0  \n",
       "2            0         0.0  \n",
       "3            0         0.0  \n",
       "4            0         0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Prepare the data\n",
    "\n",
    "def prep_data(df):\n",
    "    #Prepare the data\n",
    "    df_dummy = df[['id','veh_value','exposure','claim_count','claim_cost']].copy()\n",
    "    #Make dummy variables using Pandas\n",
    "    df_dummy = pd.concat([df_dummy,pd.get_dummies(df['veh_age'],drop_first=True,prefix=\"veh_age\")],axis=1)\n",
    "    df_dummy = pd.concat([df_dummy,pd.get_dummies(df['dr_age'],drop_first=True,prefix=\"dr_age\")],axis=1)\n",
    "    df_dummy = pd.concat([df_dummy,pd.get_dummies(df['veh_body'],drop_first=True)],axis=1)\n",
    "    df_dummy = pd.concat([df_dummy,pd.get_dummies(df['gender'],drop_first=True)],axis=1)\n",
    "    df_dummy = pd.concat([df_dummy,pd.get_dummies(df['area'],drop_first=True)],axis=1)\n",
    "    #Normalize the Vehicle Value\n",
    "    df_dummy['veh_value'] = df_dummy['veh_value']/df_dummy['veh_value'].max()\n",
    "    \n",
    "    #We are trying to predict whether there is claim or no claim\n",
    "    df_dummy['claim_count'] = df_dummy['claim_count'].apply(lambda x: 1 if x>0 else 0)\n",
    "    return(df_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Kangaroo_train.csv')\n",
    "df_valid = pd.read_csv('Kangaroo_valid.csv')\n",
    "\n",
    "#We create a separate X_train and X_test dataset because we would require the categorical variables in the original dataset later \n",
    "#X_train and X_test dataframes have only dummy variables\n",
    "X_train = prep_data(df_train)\n",
    "X_test = prep_data(df_valid)\n",
    "\n",
    "#Create two additional columns for the individual probabilities of claim (prob1) and no-claim (prob0)\n",
    "X_train['prob0'] = np.zeros(len(X_train))\n",
    "X_train['prob1'] = np.zeros(len(X_train))\n",
    "\n",
    "X_test['prob0'] = np.zeros(len(X_test))\n",
    "X_test['prob1'] = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.58      0.72     21079\n",
      "          1       0.10      0.64      0.17      1550\n",
      "\n",
      "avg / total       0.90      0.58      0.68     22629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In the first part, we use Logistic Regression to get the probabilities of claim vs no-claim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(C=1000, class_weight='balanced')\n",
    "\n",
    "n=10\n",
    "\n",
    "for i in range (0,n):\n",
    "    \n",
    "    #Choose 3000 Negative Classes\n",
    "    X_train_temp = X_train.loc[np.random.choice(X_train[X_train['claim_count']==0].index, 3000, replace = False)]\n",
    "    #Choose 3000 Positive Classes\n",
    "    X_train_pos = X_train.loc[np.random.choice(X_train[X_train['claim_count']==1].index, 3000, replace = True)]\n",
    "    #Append the positive classes \n",
    "    X_train_temp = X_train_temp.append(X_train_pos, ignore_index=True)\n",
    "\n",
    "    #Separate into X and Y to train the model\n",
    "    y_train_temp = X_train_temp['claim_count']\n",
    "    X_train_temp.drop(['id','claim_count','claim_cost','prob0','prob1'], axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    #Fit the Logistic Regression Model\n",
    "    logmodel.fit(X_train_temp,y_train_temp)\n",
    "    X_train[['prob0','prob1']] = X_train[['prob0','prob1']] + logmodel.predict_proba(X_train.drop(['id','claim_count','claim_cost','prob0','prob1'],axis=1))\n",
    "    X_test[['prob0','prob1']] = X_test[['prob0','prob1']] + logmodel.predict_proba(X_test.drop(['id','claim_count','claim_cost','prob0','prob1'],axis=1))\n",
    "\n",
    "#Divide the log_proba and log_probb values by 10 to get the average log probabilities\n",
    "X_train['prob0']=X_train['prob0']/n\n",
    "X_train['prob1']=X_train['prob1']/n\n",
    "\n",
    "X_test['prob0']=X_test['prob0']/n\n",
    "X_test['prob1']=X_test['prob1']/n\n",
    "    \n",
    "#Check the metrics on training and test data\n",
    "logProb = 1\n",
    "temp = logProb > (X_test['prob0']/X_test['prob1'])\n",
    "X_test['predicted_claim_count']= [1 if (p==True) else 0 for p in temp]\n",
    "\n",
    "#Metrics on Test set\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(X_test['claim_count'],X_test['predicted_claim_count']))\n",
    "X_test.drop('predicted_claim_count',axis=1,inplace=True)\n",
    "\n",
    "#Calculate Claim Frequency for Test Set\n",
    "X_test['predicted_freq']= X_test['prob1'].divide(X_test['prob0'])\n",
    "X_test['predicted_freq']= X_test['predicted_freq'].apply(lambda x: x**3.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/51/c1/198915b13e98b62a98f48309c41012638464651da755d941f4abe384c012/xgboost-0.82-py2.py3-none-win_amd64.whl (7.7MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\archana rao\\anaconda3\\lib\\site-packages (from xgboost) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\archana rao\\appdata\\roaming\\python\\python35\\site-packages (from xgboost) (1.15.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archana rao\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "#Part 2: Use Regression for predicting Claim Severity\n",
    "\n",
    "#Train only on the subset of positive claim counts\n",
    "X_train_regress = X_train[X_train['claim_count']>0].copy()\n",
    "y_train_regress = np.log(X_train[X_train['claim_count']>0]['claim_cost'])\n",
    "\n",
    "#Implement XGBoost for regression\n",
    "import xgboost as xgb\n",
    "num_round = 10\n",
    "\n",
    "T_train_xgb = xgb.DMatrix(X_train_regress.drop(['id','exposure','claim_count','claim_cost','prob0','prob1'],axis=1), y_train_regress)\n",
    "params = {\"objective\": \"reg:linear\"}\n",
    "gbm = xgb.train(dtrain=T_train_xgb,params=params)\n",
    "predictions = gbm.predict(xgb.DMatrix(X_test.drop(['id','exposure','claim_count','claim_cost','prob0','prob1','predicted_freq'],axis=1)))\n",
    "X_test['predicted_claim_cost']=[np.exp(p) for p in predictions]\n",
    "X_test['predicted_claim_cost']=X_test['predicted_claim_cost'].multiply(X_test['predicted_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_value_factor = {}\n",
    "for veh_value in df_train['veh_value'].unique():\n",
    "    m = len(df_train[(df_train['veh_value']==veh_value) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_value']==veh_value].index)\n",
    "    not_m = len(df_train[(df_train['veh_value']!=veh_value) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_value']!=veh_value].index)\n",
    "    veh_value_factor[veh_value]=m/not_m\n",
    "\n",
    "veh_body_factor = {}\n",
    "for veh_body in df_train['veh_body'].unique():\n",
    "    m = len(df_train[(df_train['veh_body']==veh_body) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_body']==veh_body].index)\n",
    "    not_m = len(df_train[(df_train['veh_body']!=veh_body) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_body']!=veh_body].index)\n",
    "    veh_body_factor[veh_body]=m/not_m\n",
    "    \n",
    "veh_age_factor = {}\n",
    "for veh_age in df_train['veh_age'].unique():\n",
    "    m = len(df_train[(df_train['veh_age']==veh_age) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_age']==veh_age].index)\n",
    "    not_m = len(df_train[(df_train['veh_age']!=veh_age) & (df_train['claim_count']>0)].index)/len(df_train[df_train['veh_age']!=veh_age].index)\n",
    "    veh_age_factor[veh_age]=m/not_m\n",
    "\n",
    "gender_factor = {}\n",
    "for gender in df_train['gender'].unique():\n",
    "    m = len(df_train[(df_train['gender']==gender) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['gender']==gender) & (df_train['claim_count']==0)].index)\n",
    "    not_m = len(df_train[(df_train['gender']!=gender) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['gender']!=gender) & (df_train['claim_count']==0)].index)\n",
    "    gender_factor[gender]=m/not_m\n",
    "    \n",
    "area_factor = {}\n",
    "for area in df_train['area'].unique():\n",
    "    m = len(df_train[(df_train['area']==area) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['area']==area) & (df_train['claim_count']==0)].index)\n",
    "    not_m = len(df_train[(df_train['area']!=area) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['area']!=area) & (df_train['claim_count']==0)].index)\n",
    "    area_factor[area]=m/not_m\n",
    "\n",
    "dr_age_factor = {}\n",
    "for dr_age in df_train['dr_age'].unique():\n",
    "    m = len(df_train[(df_train['dr_age']==dr_age) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['dr_age']==dr_age) & (df_train['claim_count']==0)].index)\n",
    "    not_m = len(df_train[(df_train['dr_age']!=dr_age) & (df_train['claim_count']>0)].index)/len(df_train[(df_train['dr_age']!=dr_age) & (df_train['claim_count']==0)].index)\n",
    "    dr_age_factor[dr_age]=m/not_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veh_value_filter(pos):\n",
    "    factor = veh_value_factor[pos[0]]\n",
    "    return pos[1]**factor\n",
    "\n",
    "def veh_body_filter(pos):\n",
    "    factor = veh_body_factor[pos[0]]\n",
    "    return pos[1]**factor\n",
    "\n",
    "def veh_age_filter(pos):\n",
    "    factor = veh_age_factor[pos[0]]\n",
    "    return pos[1]**factor\n",
    "\n",
    "def gender_filter(pos):\n",
    "    factor = gender_factor[pos[0]]\n",
    "    return pos[1]**factor\n",
    "\n",
    "def area_filter(pos):\n",
    "    factor = area_factor[pos[0]]\n",
    "    return pos[1]**factor\n",
    "\n",
    "def dr_age_filter(pos):\n",
    "    factor = dr_age_factor[pos[0]]\n",
    "    return pos[1]**factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['predicted_claim_cost']= X_test['predicted_claim_cost']\n",
    "\n",
    "#Use intuition to see which factors give the highest increase in the net gini\n",
    "\n",
    "#df_valid['predicted_claim_cost'] = df_valid[['veh_value','predicted_claim_cost']].apply(veh_value_filter,axis=1)\n",
    "#df_valid['predicted_claim_cost'] = df_valid[['veh_body','predicted_claim_cost']].apply(veh_body_filter,axis=1)\n",
    "#df_valid['predicted_claim_cost'] = df_valid[['veh_age','predicted_claim_cost']].apply(veh_age_filter,axis=1) \n",
    "#df_valid['predicted_claim_cost'] = df_valid[['gender','predicted_claim_cost']].apply(gender_filter,axis=1) \n",
    "df_valid['predicted_claim_cost'] = df_valid[['area','predicted_claim_cost']].apply(area_filter,axis=1) \n",
    "df_valid['predicted_claim_cost'] = df_valid[['dr_age','predicted_claim_cost']].apply(dr_age_filter,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the output csv\n",
    "output = df_valid[['id','claim_cost','predicted_claim_cost']]\n",
    "output.to_csv('valid_predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
